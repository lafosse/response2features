{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model to Transform Response Vectors into Image Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T21:44:16.268537Z",
     "iopub.status.busy": "2021-03-06T21:44:16.268301Z",
     "iopub.status.idle": "2021-03-06T21:44:16.272391Z",
     "shell.execute_reply": "2021-03-06T21:44:16.271643Z",
     "shell.execute_reply.started": "2021-03-06T21:44:16.268510Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T18:35:08.160754Z",
     "iopub.status.busy": "2021-03-06T18:35:08.160464Z",
     "iopub.status.idle": "2021-03-06T18:35:08.164394Z",
     "shell.execute_reply": "2021-03-06T18:35:08.163579Z",
     "shell.execute_reply.started": "2021-03-06T18:35:08.160716Z"
    }
   },
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T19:41:50.204756Z",
     "iopub.status.busy": "2021-03-07T19:41:50.204520Z",
     "iopub.status.idle": "2021-03-07T19:41:50.226486Z",
     "shell.execute_reply": "2021-03-07T19:41:50.225721Z",
     "shell.execute_reply.started": "2021-03-07T19:41:50.204729Z"
    }
   },
   "outputs": [],
   "source": [
    "# build neural network to predict image feature vectors based on response vectors\n",
    "class ImageFeaturePredict:\n",
    "    \n",
    "    def __init__(self,resp_vectors,image_feature_vectors):\n",
    "        \n",
    "        self.resp = resp_vectors # shape of (nCells,nFrames)\n",
    "        self.feat = image_feature_vectors # shape of (nFrames,nWavelets)\n",
    "    \n",
    "    class Network(nn.Module):\n",
    "        \n",
    "        def __init__(self,n_cells,n_wavelets,hidden_dim_list):\n",
    "            '''initialize constructed model with input layer, output layer, \n",
    "            and len(hidden_dim_list) hidden layers\n",
    "            input_layer size is number of cells in response vector\n",
    "            output_layer size is number of image features in feature vector'''\n",
    "        \n",
    "            # calling the constructor of the parent class - gets everything we need from pytorch\n",
    "            super(ImageFeaturePredict.Network, self).__init__()\n",
    "            \n",
    "            ## Define layers of network\n",
    "            # first layer input: # of cells in a response_vector\n",
    "            self.input_layer = nn.Linear(n_cells,hidden_dim_list[0])\n",
    "            \n",
    "            # add hidden layers of network based on list of dimensions for each hidden layer\n",
    "            self.hidden_layers = [] * len(hidden_dim_list)\n",
    "            for i in range(len(hidden_dim_list) - 1):\n",
    "                self.hidden_layers.append(nn.Linear(hidden_dim_list[i],hidden_dim_list[i+1]))\n",
    "            \n",
    "            # last layer output: # of Gabor wavelets/image features in a feature_vector\n",
    "            self.output_layer = nn.Linear(hidden_dim_list[-1],n_wavelets)\n",
    "            \n",
    "            # non-linear activation function between layers\n",
    "            self.tanh = nn.Tanh() # use tanh to keep activations between -1 and 1\n",
    "#             self.relu = nn.ReLU() \n",
    "        \n",
    "        def forward(self,batch):\n",
    "            '''define the forward steps in the model between the layers;\n",
    "            data batches are passed between layers after computing the non-linear transformations \n",
    "            on the activations'''\n",
    "            \n",
    "            # input layer\n",
    "            batch = self.input_layer(batch)\n",
    "            batch = self.tanh(batch)\n",
    "      \n",
    "            # computer the activations for each hidden layer\n",
    "            for h in self.hidden_layers:\n",
    "                batch = h(batch)\n",
    "                batch = self.tanh(batch)\n",
    "            \n",
    "            # output layer\n",
    "            batch = self.output_layer(batch)\n",
    "            batch = nn.functional.tanh(batch)\n",
    "            \n",
    "            return batch\n",
    "        \n",
    "\n",
    "    def train_test_network(self,test_size,batch_size,hidden_dim_list,learning_rate,n_epochs):\n",
    "            \n",
    "        ## organize data\n",
    "        # split the data into a training and test set\n",
    "        train_resp,test_resp,train_feat,test_feat = train_test_split(self.resp,self.feat,test_size=test_size,shuffle=True)\n",
    "        \n",
    "        # create data batches\n",
    "        train_resp_batches,train_feat_batches = batch_data(train_resp,train_feat,batch_size=batch_size)\n",
    "        \n",
    "        ## organize model and learning conditions\n",
    "        # construct network\n",
    "        neural_network = ImageFeaturePredict.Network(len(train_resp[0]),len(train_feat[0]),hidden_dim_list)\n",
    "        # define optimization function on network - using stochastic gradient descent (SGD)\n",
    "        optimizer = optim.SGD(neural_network.parameters(),lr=learning_rate)\n",
    "        # define loss function\n",
    "        loss_function = nn.MSELoss()\n",
    "#         loss_function = nn.CrossEntropyLoss()\n",
    "                \n",
    "        ## begin to train the network\n",
    "        neural_network.train()\n",
    "        \n",
    "        # train model over specified number of epochs\n",
    "        for iE in range(n_epochs):\n",
    "            \n",
    "            correlations = [] # keep track of performance over multiple batches of data\n",
    "            \n",
    "            # iterate over each data batch\n",
    "            for iB in range(len(train_resp_batches)):\n",
    "                \n",
    "                # pull out data batch (resp=data batch) (feat=labels)\n",
    "                resp = train_resp_batches[iB]\n",
    "                feat = train_feat_batches[iB]\n",
    "                \n",
    "                # reset optimizer\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # calculate model predictions on batch\n",
    "                predictions = neural_network(torch.tensor(resp.astype(np.float32)))\n",
    "                \n",
    "                # calculate error of prediction\n",
    "                loss = loss_function(predictions,torch.FloatTensor(feat))\n",
    "                # backward calculation step\n",
    "                loss.backward()\n",
    "                \n",
    "                # calculate and update weights of network\n",
    "                optimizer.step()\n",
    "                \n",
    "                # test model predictions at this epoch using correlation coefficient as measure of accuracy\n",
    "                for iF,prediction in enumerate(predictions.data):\n",
    "                    real = feat[iF]\n",
    "                    \n",
    "#                     print(np.min(np.asarray(real)),np.max(np.asarray(real)))\n",
    "#                     print(np.min(np.asarray(prediction)),np.max(np.asarray(prediction)))\n",
    "                    \n",
    "                    corr = pearsonr(real,np.asarray(prediction))\n",
    "                    correlations.append(corr)\n",
    "                        \n",
    "            # report prediction performance       \n",
    "            print('Average Correlation for Epoch # ' + str(iE) + ': ' + str(np.round(np.mean(correlations),2)) )\n",
    "        \n",
    "                    \n",
    "        ## evaluate the final model performance using test data\n",
    "        neural_network.eval()\n",
    "        \n",
    "        test_correlations = []\n",
    "        test_predictions = neural_network(torch.tensor(test_resp.astype(np.float32)))\n",
    "                    \n",
    "        # test model predictions using correlation coefficient as measure of accuracy\n",
    "        for iF,prediction in enumerate(predictions.data):\n",
    "            real = test_feat[iF]\n",
    "\n",
    "            corr = pearsonr(real,prediction)\n",
    "            test_correlations.append(corr)\n",
    "                    \n",
    "        # report prediction performance       \n",
    "        print('Average Correlation for Test Data: ' + str(np.round(np.mean(test_correlations),2)) )\n",
    "           \n",
    "        return neural_network\n",
    "        \n",
    "\n",
    "## Utility Functions\n",
    "def batch_data(data,labels,batch_size=16):\n",
    "    \n",
    "    data_batches = []\n",
    "    label_batches = []\n",
    "\n",
    "    for n in range(0,len(data),batch_size):\n",
    "        if n+batch_size < len(data):\n",
    "            data_batches.append(data[n:n+batch_size])\n",
    "            label_batches.append(labels[n:n+batch_size])\n",
    "\n",
    "    if len(data)%batch_size > 0:\n",
    "        data_batches.append(data[len(data)-(len(data)%batch_size):len(data)])\n",
    "        label_batches.append(labels[len(data)-(len(data)%batch_size):len(data)])\n",
    "        \n",
    "    return data_batches,label_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-06T22:36:37.983784Z",
     "iopub.status.busy": "2021-03-06T22:36:37.983532Z",
     "iopub.status.idle": "2021-03-06T22:36:38.400679Z",
     "shell.execute_reply": "2021-03-06T22:36:38.400130Z",
     "shell.execute_reply.started": "2021-03-06T22:36:37.983758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 132)\n",
      "(36000, 1248)\n",
      "132 1248\n"
     ]
    }
   ],
   "source": [
    "# load .npz of response vectors\n",
    "resp_dict = np.load('./data/response_vectors.npz')\n",
    "resp = resp_dict['response_vectors']\n",
    "resp = np.swapaxes(resp,0,1)\n",
    "print(resp.shape)\n",
    "\n",
    "# load .npz of feature vectors\n",
    "feat_dict = np.load('./data/feature_vectors.npz')\n",
    "feat = feat_dict['feature_vectors']\n",
    "feat = np.swapaxes(feat,0,1)\n",
    "print(feat.shape)\n",
    "\n",
    "nCell = resp.shape[1]\n",
    "nWavelet = feat.shape[1]\n",
    "print(nCell,nWavelet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass data to model to train and test\n",
    "- may need to split up batches in model so sampling across tilings are uniform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T19:47:22.798882Z",
     "iopub.status.busy": "2021-03-07T19:47:22.798608Z",
     "iopub.status.idle": "2021-03-07T19:47:22.803847Z",
     "shell.execute_reply": "2021-03-07T19:47:22.803084Z",
     "shell.execute_reply.started": "2021-03-07T19:47:22.798853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 318  504  690  876 1062]\n"
     ]
    }
   ],
   "source": [
    "# model training parameters\n",
    "test_size = 0.1\n",
    "batch_size = 8\n",
    "n_hidden_layers = 5\n",
    "n_epochs = 5\n",
    "learning_rate = 1\n",
    "\n",
    "dim_step = (nWavelet-nCell)//(n_hidden_layers+1)\n",
    "hidden_dim_list = np.arange(nCell+dim_step,nWavelet,dim_step)\n",
    "print(hidden_dim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T19:47:23.352991Z",
     "iopub.status.busy": "2021-03-07T19:47:23.352746Z",
     "iopub.status.idle": "2021-03-07T19:50:54.648213Z",
     "shell.execute_reply": "2021-03-07T19:50:54.647633Z",
     "shell.execute_reply.started": "2021-03-07T19:47:23.352964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Correlation for Epoch # 0: 0.44\n",
      "Average Correlation for Epoch # 1: 0.45\n",
      "Average Correlation for Epoch # 2: 0.45\n",
      "Average Correlation for Epoch # 3: 0.45\n",
      "Average Correlation for Epoch # 4: 0.45\n",
      "Average Correlation for Test Data: 0.45\n"
     ]
    }
   ],
   "source": [
    "testclass = ImageFeaturePredict(resp,feat)\n",
    "\n",
    "model = testclass.train_test_network(test_size=test_size,\n",
    "                                     batch_size=batch_size,\n",
    "                                     hidden_dim_list=hidden_dim_list,\n",
    "                                     learning_rate=learning_rate,\n",
    "                                     n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
